# Simple Math Agent - End-to-End Test Configuration
# This test starts the actual runtime/server/server.py as a subprocess
# and communicates with it via HTTP endpoints

# Prerequisites (REQUIRED):
# 1. Ollama running: ollama serve
# 2. Model available: ollama pull smollm2:135m (HuggingFaceTB/SmolLM2-135M-Instruct)
# 3. MCP server running: uvx mcp-server-calculator

# Agent server configuration
AGENT_NAME=math-agent
AGENT_PORT=8000
AGENT_LOG_LEVEL=INFO

# Agent behavior configuration
AGENT_DESCRIPTION=A simple mathematical reasoning agent
AGENT_INSTRUCTIONS=You are a helpful mathematical assistant. You have access to a calculator tool for performing calculations. Always show your reasoning and calculations clearly.

# Model API endpoint (Ollama OpenAI-compatible API)
MODEL_API_URL=http://localhost:11434/v1
MODEL_NAME=smollm2:135m

# MCP Server for calculator tools
MCP_SERVER_MATH_TOOLS_URL=http://localhost:8001

---
# Sample 4: Development Agent with Ollama Proxy
# For local development with Ollama running on host machine
# Uses LiteLLM proxy to connect to host Ollama (via Docker Desktop)
# Deploy: kubectl apply -f 4-dev-ollama-proxy-agent.yaml

apiVersion: v1
kind: Namespace
metadata:
  name: kaos-dev
  labels:
    app.kubernetes.io/part-of: kaos-sample-dev

---
# ModelAPI: LiteLLM proxy to host Ollama (WILDCARD MODE)
# Uses models: ["*"] to allow any model request to be proxied
apiVersion: kaos.tools/v1alpha1
kind: ModelAPI
metadata:
  name: dev-ollama-proxy
  namespace: kaos-dev
spec:
  mode: Proxy
  proxyConfig:
    # Wildcard mode: allow any model to be proxied to host Ollama
    models:
    - "*"
    apiBase: "http://host.docker.internal:11434"
  container:
    env:
    - name: LITELLM_LOG
      value: "INFO"

---
# MCPServer: Echo tool for testing
apiVersion: kaos.tools/v1alpha1
kind: MCPServer
metadata:
  name: dev-echo-mcp
  namespace: kaos-dev
spec:
  runtime: python-string
  params: |
    def echo(message: str) -> str:
        """Echo the provided message back."""
        return f"Echo: {message}"

---
# Agent: Development agent with proxy to host Ollama
apiVersion: kaos.tools/v1alpha1
kind: Agent
metadata:
  name: dev-agent
  namespace: kaos-dev
spec:
  modelAPI: dev-ollama-proxy
  model: "ollama/smollm2:135m"  # Required: any model works with wildcard
  mcpServers:
  - dev-echo-mcp
  config:
    description: "Development agent for testing with host Ollama"
    instructions: |
      You are a helpful assistant with access to an echo tool.
      Use the echo tool when asked to echo something.
    reasoningLoopMaxSteps: 10
  agentNetwork:
    access: []
